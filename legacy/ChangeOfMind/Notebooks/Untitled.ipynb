{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078a9cc-98c6-4740-a652-4dac20c9ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b36dc-9f41-46d0-a347-a792fa4fbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/scratch/ti12/misc/for_Ben\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e186ea-3f7a-43d5-8f73-959a54cac52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_glob = glob(f\"{data_dir}/word_times/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1b281-c282-4de5-a9bf-72d72f99abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2009ab-60c4-4aa7-b2c8-ad0e5677fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, patient in enumerate(patients):\n",
    "    word_mat = loadmat(word_glob[idx])\n",
    "    word_times[patient] = word_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96373bd8-29b9-4637-ad5a-0b4fa692af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, patient in enumerate(patients):\n",
    "    spike_path = glob(f'{data_dir}/spike_trains/*{patient}*.mat')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a1b27-b60f-4c95-bd0c-f0345d0dcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, patient in enumerate(patients):\n",
    "    spike_path = glob(f'{data_dir}/spike_trains/*{patient}*.mat')[0]\n",
    "    with h5py.File(spike_path, 'r') as f:\n",
    "        chan_info[patient] = f['chan'][:].squeeze()\n",
    "        sparse_mat = f[\"spikes\"]\n",
    "        data = sparse_mat[\"data\"][:].flatten()  # Extract nonzero values\n",
    "        ir = sparse_mat[\"ir\"][:].flatten()      # Row indices\n",
    "        jc = sparse_mat[\"jc\"][:].flatten()      # Co\n",
    "\n",
    "        # Determine the shape of the matrix (from jc array)\n",
    "        num_rows = int(ir.max() + 1)  # Max row index + 1\n",
    "        num_cols = len(jc) - 1   # The number of columns (jc's length - 1)\n",
    "\n",
    "        # Create the scipy.sparse.csc_matrix\n",
    "        sparse_matrix = sp.csc_matrix((data, ir, jc), shape=(num_rows, num_cols))\n",
    "        spike_trains[patient] = sparse_matrix\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e425c-dde5-4928-8ee2-a15c4da3f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_96 = h5py.File(yex_paths[0])\n",
    "f_99 = h5py.File(yex_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15a9c3-d53e-402a-b75d-e6cd1400eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = f_96[\"spikes96\"]\n",
    "chan = f_96[\"chan96\"][:]\n",
    "data = sparse_mat[\"data\"][:].flatten()  # Extract nonzero values\n",
    "ir = sparse_mat[\"ir\"][:].flatten()      # Row indices\n",
    "jc = sparse_mat[\"jc\"][:].flatten()      # Co\n",
    "\n",
    "# Determine the shape of the matrix (from jc array)\n",
    "num_rows = int(ir.max() + 1)  # Max row index + 1\n",
    "num_cols = len(jc) - 1   # The number of columns (jc's length - 1)\n",
    "\n",
    "# Create the scipy.sparse.csc_matrix\n",
    "sparse_matrix_96 = sp.csc_matrix((data, ir, jc), shape=(num_rows, num_cols))\n",
    "\n",
    "sparse_mat = f_99[\"spikes\"]\n",
    "\n",
    "data = sparse_mat[\"data\"][:].flatten()  # Extract nonzero values\n",
    "ir = sparse_mat[\"ir\"][:].flatten()      # Row indices\n",
    "jc = sparse_mat[\"jc\"][:].flatten()      # Co\n",
    "\n",
    "# Determine the shape of the matrix (from jc array)\n",
    "num_rows = int(ir.max() + 1)  # Max row index + 1\n",
    "num_cols = len(jc) - 1   # The number of columns (jc's length - 1)\n",
    "\n",
    "# Create the scipy.sparse.csc_matrix\n",
    "sparse_matrix_99 = sp.csc_matrix((data, ir, jc), shape=(num_rows, num_cols))\n",
    "\n",
    "sparse_matrix = sp.hstack((sparse_matrix_96, sparse_matrix_99))\n",
    "\n",
    "f_96.close()\n",
    "f_99.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21f626-507b-4455-a234-dbaa88610aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_trains[\"YEX\"] = sparse_matrix\n",
    "chan_info[\"YEX\"] = chan.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb8a15-7a81-4039-a9bb-6bb1c22337fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get ofc indices\n",
    "ofc_indices = {}\n",
    "for patient in patients:\n",
    "    try:\n",
    "        micro_df = pd.read_csv(f\"{data_dir}/micro_data/{patient}_micro_info.csv\", index_col=0)\n",
    "        ofc_indices[patient] = micro_df[\"region_symbol\"] == \"OFC\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9a548-d2a5-4bdd-92ca-1072cfc56feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofc_indices[\"UTA\"] = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "ofc_indices[\"UTC\"] = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "ofc_indices[\"UTE\"] = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "ofc_indices[\"YEW\"] = np.array([24, 25, 26, 27, 28, 29, 30, 31, 56, 57, 58, 59, 60, 61, 62, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffd83e-faf0-4961-8a0e-1da17aee09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_masks = {}\n",
    "for patient in patients:\n",
    "    chan_masks[patient] = np.isin(chan_info[patient] - 1, ofc_indices[patient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e02b3-12a6-4759-8170-fe9adcccab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mats = {}\n",
    "dur_mats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200fa9d-2c8e-49f8-818e-9cdb2e30df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in patients:\n",
    "    pt_spike_list = []\n",
    "    pt_dur_list = []\n",
    "    pt_data = word_times[patient]\n",
    "    if patient == \"YFN\":\n",
    "        pt_data = np.delete(pt_data, np.arange(2262, 2275))\n",
    "    word_stack = deque([re.sub(r\"[^\\w']+$\", \"\", word.item()).lower() for word in pt_data[\"text\"].squeeze() if word != \"NaN\"])\n",
    "    pt_spike_train = spike_trains[patient][chan_masks[patient]]\n",
    "    jdx = 0\n",
    "    for idx in range(len(word_list)):\n",
    "        if not word_stack:\n",
    "            pt_spike_list.append(np.full(pt_spike_train.shape[0], np.nan))\n",
    "            pt_dur_list.append(np.nan)\n",
    "        elif word_stack[0] == word_list[idx]:\n",
    "            start = np.round(pt_data[\"onset\"].squeeze()[jdx].item() + 80).astype(int)\n",
    "            end = np.round(pt_data[\"offset\"].squeeze()[jdx].item()).astype(int)\n",
    "            dur = end - start\n",
    "            counts = pt_spike_train[:, start:end].toarray().sum(axis=1)\n",
    "            pt_spike_list.append(counts)\n",
    "            pt_dur_list.append(dur)\n",
    "            word_stack.popleft()\n",
    "            jdx += 1\n",
    "        else:\n",
    "            pt_spike_list.append(np.full(pt_spike_train.shape[0], np.nan))\n",
    "            pt_dur_list.append(np.nan)\n",
    "    print(\"length of word stack (should be empty!!):\", len(word_stack))\n",
    "    pt_spikes[patient] = np.vstack(pt_spike_list)\n",
    "    pt_durs[patient] = np.array(pt_dur_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
